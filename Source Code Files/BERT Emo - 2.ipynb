{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT Emo - 2.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f90d8d992369466d808ed4a43b24f8e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75ae29debb224680b37ccde87c51107c","IPY_MODEL_701203a1029f407faffb883e2ed8589e","IPY_MODEL_fe5ab2d5126f4a78b538dc425c29fbfe"],"layout":"IPY_MODEL_61e39907f79e4bd1a0393f2127b7336b"}},"75ae29debb224680b37ccde87c51107c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8dd96e66f85413b8a461391d28f89d4","placeholder":"​","style":"IPY_MODEL_89b99135542844658a55698b9a6acf38","value":"Downloading: 100%"}},"701203a1029f407faffb883e2ed8589e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_326f7517eedb4d9986764975eb63d838","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fbfc5393a5524ab1bb99c502fabf5749","value":231508}},"fe5ab2d5126f4a78b538dc425c29fbfe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19915007f7474777afd88460f3bbf0e8","placeholder":"​","style":"IPY_MODEL_bf431fdc8fc74de885c7233fd7a76485","value":" 226k/226k [00:00&lt;00:00, 5.35MB/s]"}},"61e39907f79e4bd1a0393f2127b7336b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8dd96e66f85413b8a461391d28f89d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b99135542844658a55698b9a6acf38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"326f7517eedb4d9986764975eb63d838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbfc5393a5524ab1bb99c502fabf5749":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19915007f7474777afd88460f3bbf0e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf431fdc8fc74de885c7233fd7a76485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50b1e560c791482fadfd864b55e161f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db05e001120c46ababe5db3815536def","IPY_MODEL_1c884ee86ecc4c5aa667d9a2823af7c1","IPY_MODEL_f66f51ed59284b9ca27419b6b4076087"],"layout":"IPY_MODEL_4b4ccb90ae2c4dca8492eac6b9477bc2"}},"db05e001120c46ababe5db3815536def":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aedfea0d0548413491db3d1bc43148eb","placeholder":"​","style":"IPY_MODEL_3333cf048f06475bba699fee0ec3d5bd","value":"Downloading: 100%"}},"1c884ee86ecc4c5aa667d9a2823af7c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a6b2c2f8ca745f09183c29be13549f1","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d19ac9059c2414689f6bffc2d982ea1","value":28}},"f66f51ed59284b9ca27419b6b4076087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95d525288723409c96e9027b030681e9","placeholder":"​","style":"IPY_MODEL_88795106facd41fa87278da4ba5ae2af","value":" 28.0/28.0 [00:00&lt;00:00, 939B/s]"}},"4b4ccb90ae2c4dca8492eac6b9477bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aedfea0d0548413491db3d1bc43148eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3333cf048f06475bba699fee0ec3d5bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a6b2c2f8ca745f09183c29be13549f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d19ac9059c2414689f6bffc2d982ea1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95d525288723409c96e9027b030681e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88795106facd41fa87278da4ba5ae2af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"450d54acfcba40cab5b514f9c917a785":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78705ebf81624d58ac448b6e9812b5db","IPY_MODEL_f108e436e8ff4e649b919605ec635506","IPY_MODEL_3da59e2cd4774094ad67a5d0cdcdfc0e"],"layout":"IPY_MODEL_f7bf8bce53e64de18911917067c512b0"}},"78705ebf81624d58ac448b6e9812b5db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62be0328142646bb884de666f4ac33e6","placeholder":"​","style":"IPY_MODEL_c99a5292b99f42658bf990cb01953e8f","value":"Downloading: 100%"}},"f108e436e8ff4e649b919605ec635506":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7927c7b9302a43b6b9776f615f6089d8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f42cafe8ce44e34bd0a8f863823a380","value":570}},"3da59e2cd4774094ad67a5d0cdcdfc0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b2118adc0c94cb7916ec47d2129868f","placeholder":"​","style":"IPY_MODEL_f8dbf6939a394dedb642a66838626a14","value":" 570/570 [00:00&lt;00:00, 16.6kB/s]"}},"f7bf8bce53e64de18911917067c512b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62be0328142646bb884de666f4ac33e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c99a5292b99f42658bf990cb01953e8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7927c7b9302a43b6b9776f615f6089d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f42cafe8ce44e34bd0a8f863823a380":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7b2118adc0c94cb7916ec47d2129868f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8dbf6939a394dedb642a66838626a14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be098ca0556d415aa606a219a3e955ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_071946ac7b064dad91a2c32cb3559a48","IPY_MODEL_b915eb16cfff4ddf9b9f0de10d0f1d30","IPY_MODEL_ba87f96b151446b98be04482c48e17c3"],"layout":"IPY_MODEL_fe9e789ff888445684360c33bce8dc74"}},"071946ac7b064dad91a2c32cb3559a48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c1dc5575a5d426381cfc0682586a80e","placeholder":"​","style":"IPY_MODEL_60c15023b0fe45459c29ea5abb0e18fb","value":"Downloading: 100%"}},"b915eb16cfff4ddf9b9f0de10d0f1d30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a299af2bb2e4954b6a144e58cca44b1","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f6d5c28b0104a51a54d88c15bac3d5a","value":440473133}},"ba87f96b151446b98be04482c48e17c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33a156637975461582f50b320fc69f6b","placeholder":"​","style":"IPY_MODEL_dbf934b7c1624f3daf55d12362489016","value":" 420M/420M [00:12&lt;00:00, 54.9MB/s]"}},"fe9e789ff888445684360c33bce8dc74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c1dc5575a5d426381cfc0682586a80e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60c15023b0fe45459c29ea5abb0e18fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a299af2bb2e4954b6a144e58cca44b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f6d5c28b0104a51a54d88c15bac3d5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33a156637975461582f50b320fc69f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbf934b7c1624f3daf55d12362489016":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["BERT EXTRCATOR CODE HAS BEEN ADAPTED FROM - https://github.com/Ighina/MultiModalSA/blob/master/utils/BERT_embeddings_extractor.py"],"metadata":{"id":"H0pjO0eTzMoO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RuqdZnIoCl2","executionInfo":{"status":"ok","timestamp":1650166850568,"user_tz":-240,"elapsed":146968,"user":{"displayName":"ayushi amin","userId":"16559211414148572210"}},"outputId":"3147f630-2702-4fdb-e13e-5ad33e03a40a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m95u_JJi0XYQ","executionInfo":{"status":"ok","timestamp":1650166909178,"user_tz":-240,"elapsed":31345,"user":{"displayName":"ayushi amin","userId":"16559211414148572210"}},"outputId":"24e4afa5-582e-4c0c-f47b-72409fc09d44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-3n3bxmp7\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-3n3bxmp7\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 26.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 57.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=4004577 sha256=2fcfc3d5f6031df1fb3d93cdfcd7334acd8333077b4f1acb948d4609d6590eff\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cthe0xsd/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.19.0.dev0\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nGaXJuf0gTu","executionInfo":{"status":"ok","timestamp":1650166931196,"user_tz":-240,"elapsed":7109,"user":{"displayName":"ayushi amin","userId":"16559211414148572210"}},"outputId":"a321c64f-782f-49d9-f22f-337297223917"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.0.dev0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["import transformers\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n","\n","import copy\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report"],"metadata":{"id":"kRFfAHaV03L-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(transformers.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBgHiIeW09yO","executionInfo":{"status":"ok","timestamp":1650166944064,"user_tz":-240,"elapsed":25,"user":{"displayName":"ayushi amin","userId":"16559211414148572210"}},"outputId":"2dabdcab-d7c5-4511-ac69-aefc3b4699f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4.19.0.dev0\n"]}]},{"cell_type":"markdown","source":["call cuda"],"metadata":{"id":"BhgvOWA4eMC9"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"Bd2HhDCY1AOu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/data/rawSentence-Train-Final.csv\")\n","display(train_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"uqdDn-TB1Gy-","executionInfo":{"status":"ok","timestamp":1650136044132,"user_tz":-240,"elapsed":999,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"5368f373-1869-4684-c2c6-1adee6ab0417"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length\n","0  independence we are only bound by human rights...               19\n","1  sp sp sp sp we scrutinize what governments wha...               20\n","2  sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...               20\n","3  sp sp sp sp work we help the states to impleme...               20\n","4  us to do that effectively we need to be indepe...               20"],"text/html":["\n","  <div id=\"df-5b6b3f36-afae-464d-a7f4-a6770c13fd9f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>independence we are only bound by human rights...</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp we scrutinize what governments wha...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp work we help the states to impleme...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>us to do that effectively we need to be indepe...</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b6b3f36-afae-464d-a7f4-a6770c13fd9f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5b6b3f36-afae-464d-a7f4-a6770c13fd9f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5b6b3f36-afae-464d-a7f4-a6770c13fd9f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["emo_df_train = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/csv_files/eTrain.csv\")\n","display(emo_df_train.head()) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"SdfrBwY513vd","executionInfo":{"status":"ok","timestamp":1650136044135,"user_tz":-240,"elapsed":182,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"74d31f3e-c6dd-4298-a4ac-35232a5250fc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["   Anger  Disgust  Fear  Happy  Sad  Surprise\n","0    0.0      1.0   0.0    0.0  0.0       0.0\n","1    1.0      0.0   0.0    0.0  0.0       0.0\n","2    1.0      0.0   0.0    0.0  0.0       0.0\n","3    1.0      0.0   0.0    0.0  0.0       0.0\n","4    1.0      0.0   0.0    0.0  0.0       0.0"],"text/html":["\n","  <div id=\"df-16e6c6b7-e938-4767-8e99-8fd9cfa19ec9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16e6c6b7-e938-4767-8e99-8fd9cfa19ec9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-16e6c6b7-e938-4767-8e99-8fd9cfa19ec9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-16e6c6b7-e938-4767-8e99-8fd9cfa19ec9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["train_df_final = pd.concat([train_df, emo_df_train], axis = 1)\n","display(train_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"69MfKw7917bV","executionInfo":{"status":"ok","timestamp":1650136044138,"user_tz":-240,"elapsed":171,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"dcafb3cb-065d-4536-e95a-2b00cf020c9c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length  Anger  \\\n","0  independence we are only bound by human rights...               19    0.0   \n","1  sp sp sp sp we scrutinize what governments wha...               20    1.0   \n","2  sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...               20    1.0   \n","3  sp sp sp sp work we help the states to impleme...               20    1.0   \n","4  us to do that effectively we need to be indepe...               20    1.0   \n","\n","   Disgust  Fear  Happy  Sad  Surprise  \n","0      1.0   0.0    0.0  0.0       0.0  \n","1      0.0   0.0    0.0  0.0       0.0  \n","2      0.0   0.0    0.0  0.0       0.0  \n","3      0.0   0.0    0.0  0.0       0.0  \n","4      0.0   0.0    0.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-a54eff1d-00ad-49d4-ad41-1bb7c9e34aa4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>independence we are only bound by human rights...</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp we scrutinize what governments wha...</td>\n","      <td>20</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...</td>\n","      <td>20</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp work we help the states to impleme...</td>\n","      <td>20</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>us to do that effectively we need to be indepe...</td>\n","      <td>20</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a54eff1d-00ad-49d4-ad41-1bb7c9e34aa4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a54eff1d-00ad-49d4-ad41-1bb7c9e34aa4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a54eff1d-00ad-49d4-ad41-1bb7c9e34aa4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["train_df_final.drop(\"Sentence Length\", axis=1, inplace=True)\n","display(train_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ClLvp5KF19h8","executionInfo":{"status":"ok","timestamp":1650136044140,"user_tz":-240,"elapsed":170,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"b3c92695-62d7-4473-bb15-4dedad317b2b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Anger  Disgust  Fear  \\\n","0  independence we are only bound by human rights...    0.0      1.0   0.0   \n","1  sp sp sp sp we scrutinize what governments wha...    1.0      0.0   0.0   \n","2  sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...    1.0      0.0   0.0   \n","3  sp sp sp sp work we help the states to impleme...    1.0      0.0   0.0   \n","4  us to do that effectively we need to be indepe...    1.0      0.0   0.0   \n","\n","   Happy  Sad  Surprise  \n","0    0.0  0.0       0.0  \n","1    0.0  0.0       0.0  \n","2    0.0  0.0       0.0  \n","3    0.0  0.0       0.0  \n","4    0.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-024796cb-42c6-4641-9615-9cd5497f5c63\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>independence we are only bound by human rights...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp we scrutinize what governments wha...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp inde...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp work we help the states to impleme...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>us to do that effectively we need to be indepe...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-024796cb-42c6-4641-9615-9cd5497f5c63')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-024796cb-42c6-4641-9615-9cd5497f5c63 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-024796cb-42c6-4641-9615-9cd5497f5c63');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["print(train_df_final.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XYQoGe42Cel","executionInfo":{"status":"ok","timestamp":1650136044148,"user_tz":-240,"elapsed":168,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"788f156e-fef3-4d8f-e4d3-430abe6bd141"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(15290, 7)\n"]}]},{"cell_type":"code","source":["valid_df = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/data/rawSentence-Valid-Final.csv\")\n","display(valid_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"RJb5aPaG2I5k","executionInfo":{"status":"ok","timestamp":1650136044763,"user_tz":-240,"elapsed":765,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"9963aa59-4ef9-485e-928f-8c7dce841a4f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length\n","0  sp sp sp sp sp albums now you might wonder why...               20\n","1  sp sp sp sp sp sp sp sp sp sp this is another ...               20\n","2  albums like this that i always misplace or tha...               20\n","3  sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...               20\n","4  sp sp sp out there that will give you an oppor...               20"],"text/html":["\n","  <div id=\"df-f0c49522-0902-41fa-8959-c3b27511d4e1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sp sp sp sp sp albums now you might wonder why...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp this is another ...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>albums like this that i always misplace or tha...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp out there that will give you an oppor...</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0c49522-0902-41fa-8959-c3b27511d4e1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f0c49522-0902-41fa-8959-c3b27511d4e1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f0c49522-0902-41fa-8959-c3b27511d4e1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["emo_df_valid = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/csv_files/eValid.csv\")\n","display(emo_df_valid.head()) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"TEIIihQ22KTH","executionInfo":{"status":"ok","timestamp":1650136044821,"user_tz":-240,"elapsed":445,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"5e211703-1640-445e-a352-6c0f870db0b0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["   Anger  Disgust  Fear  Happy  Sad  Surprise\n","0    0.0      0.0   0.0    1.0  0.0       0.0\n","1    0.0      0.0   0.0    0.0  1.0       0.0\n","2    0.0      0.0   0.0    1.0  0.0       0.0\n","3    0.0      0.0   0.0    1.0  0.0       0.0\n","4    0.0      0.0   0.0    1.0  0.0       0.0"],"text/html":["\n","  <div id=\"df-42e43f13-2723-459c-a926-648a807626dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42e43f13-2723-459c-a926-648a807626dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-42e43f13-2723-459c-a926-648a807626dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-42e43f13-2723-459c-a926-648a807626dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["valid_df_final = pd.concat([valid_df, emo_df_valid], axis = 1)\n","display(valid_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"SzhGKzza2PBU","executionInfo":{"status":"ok","timestamp":1650136044822,"user_tz":-240,"elapsed":443,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"050b8982-86a4-449a-9701-806645cd1bcf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length  Anger  \\\n","0  sp sp sp sp sp albums now you might wonder why...               20    0.0   \n","1  sp sp sp sp sp sp sp sp sp sp this is another ...               20    0.0   \n","2  albums like this that i always misplace or tha...               20    0.0   \n","3  sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...               20    0.0   \n","4  sp sp sp out there that will give you an oppor...               20    0.0   \n","\n","   Disgust  Fear  Happy  Sad  Surprise  \n","0      0.0   0.0    1.0  0.0       0.0  \n","1      0.0   0.0    0.0  1.0       0.0  \n","2      0.0   0.0    1.0  0.0       0.0  \n","3      0.0   0.0    1.0  0.0       0.0  \n","4      0.0   0.0    1.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-eff55e91-0b58-4123-91a8-50f561be4dd0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sp sp sp sp sp albums now you might wonder why...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp this is another ...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>albums like this that i always misplace or tha...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp out there that will give you an oppor...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eff55e91-0b58-4123-91a8-50f561be4dd0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eff55e91-0b58-4123-91a8-50f561be4dd0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eff55e91-0b58-4123-91a8-50f561be4dd0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["valid_df_final.drop(\"Sentence Length\", axis=1, inplace=True)\n","display(valid_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"g7phylAO2Rr1","executionInfo":{"status":"ok","timestamp":1650136044826,"user_tz":-240,"elapsed":444,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"a02f312d-4b9c-47a4-9da6-e049fddb2171"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Anger  Disgust  Fear  \\\n","0  sp sp sp sp sp albums now you might wonder why...    0.0      0.0   0.0   \n","1  sp sp sp sp sp sp sp sp sp sp this is another ...    0.0      0.0   0.0   \n","2  albums like this that i always misplace or tha...    0.0      0.0   0.0   \n","3  sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...    0.0      0.0   0.0   \n","4  sp sp sp out there that will give you an oppor...    0.0      0.0   0.0   \n","\n","   Happy  Sad  Surprise  \n","0    1.0  0.0       0.0  \n","1    0.0  1.0       0.0  \n","2    1.0  0.0       0.0  \n","3    1.0  0.0       0.0  \n","4    1.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-918b3576-82f9-43e9-b488-a09282fa7f83\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sp sp sp sp sp albums now you might wonder why...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp this is another ...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>albums like this that i always misplace or tha...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp sp sp sp sp sp sp sp how ...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp out there that will give you an oppor...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-918b3576-82f9-43e9-b488-a09282fa7f83')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-918b3576-82f9-43e9-b488-a09282fa7f83 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-918b3576-82f9-43e9-b488-a09282fa7f83');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["print(valid_df_final.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnGlLjlX2ZQk","executionInfo":{"status":"ok","timestamp":1650136044827,"user_tz":-240,"elapsed":322,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"f5535532-40d3-412b-839c-dd1e35067a00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(2291, 7)\n"]}]},{"cell_type":"code","source":["test_df = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/data/rawSentence-Test-Final.csv\")\n","display(test_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"kMGwU5LE2hYf","executionInfo":{"status":"ok","timestamp":1650136046156,"user_tz":-240,"elapsed":1617,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"1b041898-cf32-4b6a-e354-c2a079b0cce6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length\n","0  what doing sp not talking about just going int...               19\n","1  super connectors that help businesses via thei...               20\n","2  sp sp sp sp now you see this online with big b...               20\n","3  sp sp sp sp sp sp sp benefits the first being ...               19\n","4  sp sp sp sp sp sp sp sp sp them so how do you ...               20"],"text/html":["\n","  <div id=\"df-6ed87d2f-f91e-45b2-b44e-f63e5b574a79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what doing sp not talking about just going int...</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>super connectors that help businesses via thei...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp now you see this online with big b...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp benefits the first being ...</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp sp sp sp sp sp sp them so how do you ...</td>\n","      <td>20</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ed87d2f-f91e-45b2-b44e-f63e5b574a79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ed87d2f-f91e-45b2-b44e-f63e5b574a79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ed87d2f-f91e-45b2-b44e-f63e5b574a79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["emo_df_test = pd.read_csv(\"/content/drive/MyDrive/Dissertation/dataset/csv_files/eTest.csv\")\n","display(emo_df_test.head()) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JJseT3Gr2nVU","executionInfo":{"status":"ok","timestamp":1650136046205,"user_tz":-240,"elapsed":507,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"8315da52-7adb-4eb1-a7c2-1a968102e49b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["   Anger  Disgust  Fear  Happy  Sad  Surprise\n","0    0.0      0.0   0.0    1.0  0.0       0.0\n","1    0.0      0.0   0.0    1.0  0.0       0.0\n","2    0.0      0.0   0.0    1.0  0.0       0.0\n","3    0.0      0.0   0.0    1.0  0.0       0.0\n","4    0.0      0.0   0.0    1.0  0.0       0.0"],"text/html":["\n","  <div id=\"df-df3e9309-ec11-418d-bc0f-04998578111d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df3e9309-ec11-418d-bc0f-04998578111d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-df3e9309-ec11-418d-bc0f-04998578111d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df3e9309-ec11-418d-bc0f-04998578111d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["test_df_final = pd.concat([test_df, emo_df_test], axis = 1)\n","display(test_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3NfwtoOq2qX_","executionInfo":{"status":"ok","timestamp":1650136046209,"user_tz":-240,"elapsed":502,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"294d7c67-7575-466d-8033-5ec0cd8db808"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Sentence Length  Anger  \\\n","0  what doing sp not talking about just going int...               19    0.0   \n","1  super connectors that help businesses via thei...               20    0.0   \n","2  sp sp sp sp now you see this online with big b...               20    0.0   \n","3  sp sp sp sp sp sp sp benefits the first being ...               19    0.0   \n","4  sp sp sp sp sp sp sp sp sp them so how do you ...               20    0.0   \n","\n","   Disgust  Fear  Happy  Sad  Surprise  \n","0      0.0   0.0    1.0  0.0       0.0  \n","1      0.0   0.0    1.0  0.0       0.0  \n","2      0.0   0.0    1.0  0.0       0.0  \n","3      0.0   0.0    1.0  0.0       0.0  \n","4      0.0   0.0    1.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-f2402587-faac-4d4c-9494-d046bd876265\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Sentence Length</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what doing sp not talking about just going int...</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>super connectors that help businesses via thei...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp now you see this online with big b...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp benefits the first being ...</td>\n","      <td>19</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp sp sp sp sp sp sp them so how do you ...</td>\n","      <td>20</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2402587-faac-4d4c-9494-d046bd876265')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2402587-faac-4d4c-9494-d046bd876265 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2402587-faac-4d4c-9494-d046bd876265');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["test_df_final.drop(\"Sentence Length\", axis=1, inplace=True)\n","display(test_df_final.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"EKqE3q6E2v_8","executionInfo":{"status":"ok","timestamp":1650136046210,"user_tz":-240,"elapsed":494,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"c1b747a2-76de-4c08-c802-45b855b4cff0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                                            Sentence  Anger  Disgust  Fear  \\\n","0  what doing sp not talking about just going int...    0.0      0.0   0.0   \n","1  super connectors that help businesses via thei...    0.0      0.0   0.0   \n","2  sp sp sp sp now you see this online with big b...    0.0      0.0   0.0   \n","3  sp sp sp sp sp sp sp benefits the first being ...    0.0      0.0   0.0   \n","4  sp sp sp sp sp sp sp sp sp them so how do you ...    0.0      0.0   0.0   \n","\n","   Happy  Sad  Surprise  \n","0    1.0  0.0       0.0  \n","1    1.0  0.0       0.0  \n","2    1.0  0.0       0.0  \n","3    1.0  0.0       0.0  \n","4    1.0  0.0       0.0  "],"text/html":["\n","  <div id=\"df-76b5ac21-831b-4d63-b58a-b439382f5033\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence</th>\n","      <th>Anger</th>\n","      <th>Disgust</th>\n","      <th>Fear</th>\n","      <th>Happy</th>\n","      <th>Sad</th>\n","      <th>Surprise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what doing sp not talking about just going int...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>super connectors that help businesses via thei...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sp sp sp sp now you see this online with big b...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sp sp sp sp sp sp sp benefits the first being ...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sp sp sp sp sp sp sp sp sp them so how do you ...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76b5ac21-831b-4d63-b58a-b439382f5033')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-76b5ac21-831b-4d63-b58a-b439382f5033 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-76b5ac21-831b-4d63-b58a-b439382f5033');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["print(test_df_final.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1zdNhx8T2x5d","executionInfo":{"status":"ok","timestamp":1650136046212,"user_tz":-240,"elapsed":407,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"9804ec13-94ef-47cd-e2da-95bd2ce64a9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(4832, 7)\n"]}]},{"cell_type":"code","source":["sentences_train = train_df_final.Sentence.values"],"metadata":{"id":"K9lejPoe3ahs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_scores_train = train_df_final.iloc[:,1:].values\n","print(emotion_scores_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jk-a7_TY32cC","executionInfo":{"status":"ok","timestamp":1650136046222,"user_tz":-240,"elapsed":336,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"e8a0b512-643f-42ff-e15c-e11a8f845db3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 1. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," ...\n"," [0. 0. 1. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]]\n"]}]},{"cell_type":"code","source":["# for i, value in enumerate(emotion_scores):\n","#   score_list = []\n","#   for score in value:\n","#     score_list.append(int(score))\n","#   emotion_scores[i] = score_list\n","# print(emotion_scores)"],"metadata":{"id":"dBmVJX3SBGj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences_valid = valid_df_final.Sentence.values"],"metadata":{"id":"czgYQIEnE9oq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_scores_valid = valid_df_final.iloc[:,1:].values\n","print(emotion_scores_valid)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZPSfRFQFHWL","executionInfo":{"status":"ok","timestamp":1650136046228,"user_tz":-240,"elapsed":310,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"8e1aed2f-911e-4aff-c976-eb7d8487eacd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," ...\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0.]]\n"]}]},{"cell_type":"code","source":["tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["f90d8d992369466d808ed4a43b24f8e9","75ae29debb224680b37ccde87c51107c","701203a1029f407faffb883e2ed8589e","fe5ab2d5126f4a78b538dc425c29fbfe","61e39907f79e4bd1a0393f2127b7336b","d8dd96e66f85413b8a461391d28f89d4","89b99135542844658a55698b9a6acf38","326f7517eedb4d9986764975eb63d838","fbfc5393a5524ab1bb99c502fabf5749","19915007f7474777afd88460f3bbf0e8","bf431fdc8fc74de885c7233fd7a76485","50b1e560c791482fadfd864b55e161f6","db05e001120c46ababe5db3815536def","1c884ee86ecc4c5aa667d9a2823af7c1","f66f51ed59284b9ca27419b6b4076087","4b4ccb90ae2c4dca8492eac6b9477bc2","aedfea0d0548413491db3d1bc43148eb","3333cf048f06475bba699fee0ec3d5bd","4a6b2c2f8ca745f09183c29be13549f1","2d19ac9059c2414689f6bffc2d982ea1","95d525288723409c96e9027b030681e9","88795106facd41fa87278da4ba5ae2af","450d54acfcba40cab5b514f9c917a785","78705ebf81624d58ac448b6e9812b5db","f108e436e8ff4e649b919605ec635506","3da59e2cd4774094ad67a5d0cdcdfc0e","f7bf8bce53e64de18911917067c512b0","62be0328142646bb884de666f4ac33e6","c99a5292b99f42658bf990cb01953e8f","7927c7b9302a43b6b9776f615f6089d8","9f42cafe8ce44e34bd0a8f863823a380","7b2118adc0c94cb7916ec47d2129868f","f8dbf6939a394dedb642a66838626a14"]},"id":"bGJqwj1QFwUp","executionInfo":{"status":"ok","timestamp":1650136046815,"user_tz":-240,"elapsed":881,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"91c303ce-88c4-4725-8084-496bb760df7c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f90d8d992369466d808ed4a43b24f8e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b1e560c791482fadfd864b55e161f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"450d54acfcba40cab5b514f9c917a785"}},"metadata":{}}]},{"cell_type":"code","source":["# Testing the tokenizer\n","test_sent = \"Hello! Welcome to Dubai\"\n","test_sent_tokens = tokenizer.tokenize(test_sent)\n","test_sent_token_ids = tokenizer.convert_tokens_to_ids(test_sent_tokens)\n","\n","print('Sentence: ', test_sent)\n","print('Tokens: ', test_sent_tokens)\n","print('Token IDs: ', test_sent_token_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sddrmlOF5g5","executionInfo":{"status":"ok","timestamp":1650136046816,"user_tz":-240,"elapsed":99,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"4c6c6675-caac-4231-ae85-cbad0101f775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence:  Hello! Welcome to Dubai\n","Tokens:  ['hello', '!', 'welcome', 'to', 'dubai']\n","Token IDs:  [7592, 999, 6160, 2000, 11558]\n"]}]},{"cell_type":"code","source":["tokenizer.sep_token, tokenizer.sep_token_id  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cg3XtiFrF84s","executionInfo":{"status":"ok","timestamp":1650136046817,"user_tz":-240,"elapsed":80,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"615128a5-1035-4751-d350-7701c7c71a83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('[SEP]', 102)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["tokenizer.cls_token, tokenizer.cls_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Efr-95rvF_9I","executionInfo":{"status":"ok","timestamp":1650136046819,"user_tz":-240,"elapsed":64,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"0f00ea66-5196-43f7-b264-58bf0c83d1ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('[CLS]', 101)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["tokenizer.pad_token, tokenizer.pad_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFcN6WynGCey","executionInfo":{"status":"ok","timestamp":1650136046820,"user_tz":-240,"elapsed":54,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"46bfa130-06a8-45d7-d45e-825862bf8799"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('[PAD]', 0)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["tokenizer.unk_token, tokenizer.unk_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GOK-qGizGEW1","executionInfo":{"status":"ok","timestamp":1650136046823,"user_tz":-240,"elapsed":45,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"bd8e06f7-f01e-41f7-9704-c31c2c4432ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('[UNK]', 100)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["max_len_sent = 0\n","\n","for text in sentences_train:\n","\n","    token_ids = tokenizer.encode(text, add_special_tokens=True)\n","    max_len_sent = max(max_len_sent, len(token_ids))\n","\n","print('Length of the longest sentence : ', max_len_sent)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOOeKxMmGMxi","executionInfo":{"status":"ok","timestamp":1650136059927,"user_tz":-240,"elapsed":13145,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"ea72527e-6e0f-4a8d-b2f0-2551adbd5084"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of the longest sentence :  30\n"]}]},{"cell_type":"code","source":["MAX_LEN = 45\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 32"],"metadata":{"id":"4WoFXM4FJs2F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class emoClass(Dataset):\n","  def __init__(self, datFrame, sentence, emo_score, tokenizer, max_len):\n","    self.datFrame = datFrame\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","    self.sent = sentence\n","    self.emotions = emo_score\n","  \n","  def __len__(self):\n","    return len(self.datFrame)\n","\n","  def __getitem__(self, index):\n","    sentence = self.sent[index]\n","\n","    encoded_sentence = self.tokenizer.encode_plus(\n","          sentence,\n","          add_special_tokens = True, \n","          max_length = self.max_len,\n","          pad_to_max_length = True,\n","          return_attention_mask = True, \n","          return_tensors = 'pt',\n","      )\n","\n","    input_ids = encoded_sentence['input_ids']\n","    attention_mask = encoded_sentence['attention_mask']\n","\n","    return {\n","            'sentence':sentence,\n","            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n","            'emotion_scores': torch.tensor(self.emotions[index], dtype=torch.float)\n","        }"],"metadata":{"id":"CY75jYe7InsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = emoClass(train_df_final, sentences_train, emotion_scores_train, tokenizer, MAX_LEN)\n","print(train_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pJXouJ-JxRE","executionInfo":{"status":"ok","timestamp":1650136059930,"user_tz":-240,"elapsed":69,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"2bd45815-f6a7-4a74-f87e-6a33ec9acdda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["{'sentence': 'independence we are only bound by human rights that is our standard what we apply in our work we', 'input_ids': tensor([[ 101, 4336, 2057, 2024, 2069, 5391, 2011, 2529, 2916, 2008, 2003, 2256,\n","         3115, 2054, 2057, 6611, 1999, 2256, 2147, 2057,  102,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'emotion_scores': tensor([0., 1., 0., 0., 0., 0.])}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}]},{"cell_type":"code","source":["valid_dataset = emoClass(valid_df_final, sentences_valid, emotion_scores_valid, tokenizer, MAX_LEN)\n","print(valid_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcU2BFcHLFYN","executionInfo":{"status":"ok","timestamp":1650136059931,"user_tz":-240,"elapsed":58,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"ac1ddcc1-6a85-4af4-e5ea-b98cb311d5d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'sentence': 'sp sp sp sp sp albums now you might wonder why are you buying your favorite albums again i have', 'input_ids': tensor([[  101, 11867, 11867, 11867, 11867, 11867,  4042,  2085,  2017,  2453,\n","          4687,  2339,  2024,  2017,  9343,  2115,  5440,  4042,  2153,  1045,\n","          2031,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'emotion_scores': tensor([0., 0., 0., 1., 0., 0.])}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}]},{"cell_type":"code","source":["loader_train_data = DataLoader(\n","              train_dataset,\n","              sampler = torch.utils.data.SequentialSampler(train_dataset),\n","              batch_size = TRAIN_BATCH_SIZE\n","          )"],"metadata":{"id":"byff3V1TeFBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader_valid_data = DataLoader(\n","              valid_dataset,\n","              sampler = torch.utils.data.SequentialSampler(valid_dataset),\n","              batch_size = VALID_BATCH_SIZE\n","          )"],"metadata":{"id":"l50z8z-7ePs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","from transformers import BertForSequenceClassification, AdamW, BertConfig, BertPreTrainedModel, BertModel"],"metadata":{"id":"bu6cZ3zqebKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiLabel_BertForSequenceClassification(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super(MultiLabel_BertForSequenceClassification, self).__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.bert = BertModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(768, self.config.num_labels)\n","        self.init_weights()\n","\n","    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n","                position_ids=None, head_mask=None, inputs_embeds=None, labels=None,\n","                training=True, labeltask1 = None, labeltask2 = None, fine_tune=False):\n","        \n","        if fine_tune:\n","          with torch.no_grad():\n","\n","            outputs = self.bert(input_ids,\n","                                attention_mask=attention_mask,\n","                                token_type_ids=token_type_ids,\n","                                position_ids=position_ids,\n","                                head_mask=head_mask,\n","                                inputs_embeds=inputs_embeds)\n","\n","            pooled_output = outputs[1]\n","        else:\n","            outputs = self.bert(input_ids,\n","                                attention_mask=attention_mask,\n","                                token_type_ids=token_type_ids,\n","                                position_ids=position_ids,\n","                                head_mask=head_mask,\n","                                inputs_embeds=inputs_embeds)\n","\n","            pooled_output = outputs[1]\n","            last_hidden = outputs[0]\n","\n","\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        outputs = (logits,pooled_output) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        if labels is not None:\n","          loss_fct = nn.BCEWithLogitsLoss()\n","          loss = loss_fct(logits, labels)     \n","          outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"],"metadata":{"id":"8Yh3r7hohlAx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_emotions = 6"],"metadata":{"id":"WjhNXEqrinpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MultiLabel_BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 6, \n","    output_attentions = False,\n","    output_hidden_states = True,\n",")\n","\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["be098ca0556d415aa606a219a3e955ad","071946ac7b064dad91a2c32cb3559a48","b915eb16cfff4ddf9b9f0de10d0f1d30","ba87f96b151446b98be04482c48e17c3","fe9e789ff888445684360c33bce8dc74","2c1dc5575a5d426381cfc0682586a80e","60c15023b0fe45459c29ea5abb0e18fb","5a299af2bb2e4954b6a144e58cca44b1","1f6d5c28b0104a51a54d88c15bac3d5a","33a156637975461582f50b320fc69f6b","dbf934b7c1624f3daf55d12362489016"]},"id":"tkIrOesLoi2-","executionInfo":{"status":"ok","timestamp":1650136084253,"user_tz":-240,"elapsed":24357,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"08a6e88c-e134-4dd0-cd62-abc1da65186c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be098ca0556d415aa606a219a3e955ad"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing MultiLabel_BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing MultiLabel_BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing MultiLabel_BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of MultiLabel_BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["MultiLabel_BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["LEARNING_RATE=2e-5    \n","EPOCHS=4   "],"metadata":{"id":"eG588Dq6o5HV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = 1e-8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfNCuypno6H1","executionInfo":{"status":"ok","timestamp":1650136084254,"user_tz":-240,"elapsed":17,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"31dcba02-2c42-4086-eb55-c3e98cb7a14d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["from transformers import get_linear_schedule_with_warmup\n","\n","total_steps = len(loader_train_data) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"metadata":{"id":"KfMqMNQsqV0f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"metadata":{"id":"fehiCaXZqrMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"MLA7OtPpqkBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_t0 = time.time()\n","\n","for epoch in range(0, EPOCHS):\n","  # ========================================\n","  #               Training\n","  # ========================================\n","    \n","  # Perform one full pass over the training set.\n","\n","  print(\"\")\n","  print('======== Epoch {:} / {:} ========'.format(epoch + 1, EPOCHS))\n","  print('Training...')\n","\n","  t0 = time.time()\n","\n","  total_train_loss = 0\n","\n","  model.train()\n","\n","  for step, batch in enumerate(loader_train_data):\n","\n","      if step % 40 == 0 and not step == 0:\n","          elapsed = format_time(time.time() - t0)\n","            \n","          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(loader_train_data), elapsed))\n","      \n","      input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n","      attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n","      emotion_scores = batch[\"emotion_scores\"].to(device, dtype = torch.float)\n","\n","      model.zero_grad()\n","\n","      input_ids = input_ids.squeeze(1)\n","\n","      loss, logits, _, _ = model(input_ids, attention_mask= attention_mask,\n","                             labels=emotion_scores)\n","      \n","      total_train_loss += loss.item()\n","\n","      loss.backward()\n","\n","      # Clip the norm of the gradients to 1.0.\n","      # This is to help prevent the \"exploding gradients\" problem.\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","      # Update parameters and take a step using the computed gradient.\n","      # The optimizer dictates the \"update rule\"--how the parameters are\n","      # modified based on their gradients, the learning rate, etc.\n","      optimizer.step()\n","\n","      # Update the learning rate.\n","      scheduler.step()\n","\n","\n","  # Calculate the average loss over all of the batches.\n","  avg_train_loss = total_train_loss / len(loader_train_data)            \n","    \n","  # Measure how long this epoch took.\n","  training_time = format_time(time.time() - t0)\n","\n","  print(\"\")\n","  print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n","  print(\"Training epcoh took: {:}\".format(training_time))\n","\n","  # ========================================\n","  #               Validation\n","  # ========================================\n","  # After the completion of each training epoch, measure our performance on\n","  # our validation set.\n","\n","  print(\"\")\n","  print(\"Running Validation...\")\n","\n","  t0 = time.time()\n","\n","  model.eval()\n","\n","  total_eval_loss = 0\n","  nb_eval_steps = 0\n","\n","  for batch in loader_valid_data:\n","    input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n","    attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n","    emotion_scores = batch[\"emotion_scores\"].to(device, dtype = torch.float)\n","\n","    input_ids = input_ids.squeeze(1)\n","\n","    with torch.no_grad():\n","      loss, logits, _, _ = model(input_ids, attention_mask=attention_mask,\n","                                 labels=emotion_scores)\n","      \n","      total_eval_loss += loss.item()\n","\n","      # Move logits and labels to CPU\n","      logits = logits.detach().cpu().numpy()\n","      label_ids = emotion_scores.to('cpu').numpy()\n","\n","  avg_val_loss = total_eval_loss / len(loader_valid_data)\n","\n","  if epoch>0:\n","    if avg_val_loss >= best_loss:\n","      best_loss = avg_val_loss\n","      torch.save(model.state_dict(),'/content/drive/MyDrive/Dissertation/dataset/data/finetuned_model.bin')\n","  else:\n","    best_loss = avg_val_loss\n","    torch.save(model.state_dict(),'/content/drive/MyDrive/Dissertation/dataset/data/finetuned_model.bin')\n","\n","  \n","  validation_time = format_time(time.time() - t0)\n","    \n","  print(\"Validation Loss: {0:.2f}\".format(avg_val_loss))\n","  print(\"Validation took: {:}\".format(validation_time))\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQAF_sICpCYV","executionInfo":{"status":"ok","timestamp":1650137104285,"user_tz":-240,"elapsed":568638,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"ac194d5e-faba-447e-89b8-64e98a59dcc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["  Batch    40  of    478.    Elapsed: 0:00:11.\n","  Batch    80  of    478.    Elapsed: 0:00:22.\n","  Batch   120  of    478.    Elapsed: 0:00:33.\n","  Batch   160  of    478.    Elapsed: 0:00:44.\n","  Batch   200  of    478.    Elapsed: 0:00:55.\n","  Batch   240  of    478.    Elapsed: 0:01:06.\n","  Batch   280  of    478.    Elapsed: 0:01:17.\n","  Batch   320  of    478.    Elapsed: 0:01:28.\n","  Batch   360  of    478.    Elapsed: 0:01:39.\n","  Batch   400  of    478.    Elapsed: 0:01:51.\n","  Batch   440  of    478.    Elapsed: 0:02:02.\n","\n","Average training loss: 0.32\n","Training epcoh took: 0:02:12\n","\n","Running Validation...\n","Validation Loss: 0.34\n","Validation took: 0:00:09\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    478.    Elapsed: 0:00:11.\n","  Batch    80  of    478.    Elapsed: 0:00:22.\n","  Batch   120  of    478.    Elapsed: 0:00:34.\n","  Batch   160  of    478.    Elapsed: 0:00:45.\n","  Batch   200  of    478.    Elapsed: 0:00:56.\n","  Batch   240  of    478.    Elapsed: 0:01:07.\n","  Batch   280  of    478.    Elapsed: 0:01:18.\n","  Batch   320  of    478.    Elapsed: 0:01:29.\n","  Batch   360  of    478.    Elapsed: 0:01:41.\n","  Batch   400  of    478.    Elapsed: 0:01:52.\n","  Batch   440  of    478.    Elapsed: 0:02:03.\n","\n","Average training loss: 0.30\n","Training epcoh took: 0:02:13\n","\n","Running Validation...\n","Validation Loss: 0.34\n","Validation took: 0:00:09\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    478.    Elapsed: 0:00:11.\n","  Batch    80  of    478.    Elapsed: 0:00:22.\n","  Batch   120  of    478.    Elapsed: 0:00:34.\n","  Batch   160  of    478.    Elapsed: 0:00:45.\n","  Batch   200  of    478.    Elapsed: 0:00:56.\n","  Batch   240  of    478.    Elapsed: 0:01:07.\n","  Batch   280  of    478.    Elapsed: 0:01:18.\n","  Batch   320  of    478.    Elapsed: 0:01:29.\n","  Batch   360  of    478.    Elapsed: 0:01:41.\n","  Batch   400  of    478.    Elapsed: 0:01:52.\n","  Batch   440  of    478.    Elapsed: 0:02:03.\n","\n","Average training loss: 0.29\n","Training epcoh took: 0:02:13\n","\n","Running Validation...\n","Validation Loss: 0.34\n","Validation took: 0:00:09\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    478.    Elapsed: 0:00:11.\n","  Batch    80  of    478.    Elapsed: 0:00:22.\n","  Batch   120  of    478.    Elapsed: 0:00:34.\n","  Batch   160  of    478.    Elapsed: 0:00:45.\n","  Batch   200  of    478.    Elapsed: 0:00:56.\n","  Batch   240  of    478.    Elapsed: 0:01:07.\n","  Batch   280  of    478.    Elapsed: 0:01:18.\n","  Batch   320  of    478.    Elapsed: 0:01:29.\n","  Batch   360  of    478.    Elapsed: 0:01:41.\n","  Batch   400  of    478.    Elapsed: 0:01:52.\n","  Batch   440  of    478.    Elapsed: 0:02:03.\n","\n","Average training loss: 0.29\n","Training epcoh took: 0:02:13\n","\n","Running Validation...\n","Validation Loss: 0.34\n","Validation took: 0:00:09\n","\n","Training complete!\n","Total training took 0:09:28 (h:mm:ss)\n"]}]},{"cell_type":"code","source":["feature_extractor = MultiLabel_BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", \n","    num_labels = total_emotions, \n","    output_attentions = False,\n","    output_hidden_states = True, \n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isqrnfF-qzgi","executionInfo":{"status":"ok","timestamp":1650137368965,"user_tz":-240,"elapsed":2078,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"94db9c2c-074f-432e-9e79-be1b82fd3947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing MultiLabel_BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing MultiLabel_BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing MultiLabel_BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of MultiLabel_BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["feature_extractor.load_state_dict(torch.load(\"/content/drive/MyDrive/Dissertation/dataset/data/finetuned_model.bin\"))\n","feature_extractor.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ImXCgBIl2hCn","executionInfo":{"status":"ok","timestamp":1650137412158,"user_tz":-240,"elapsed":1434,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"77d0dfe5-a5ad-41ad-cad7-9a32e8ffa8b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiLabel_BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["EPOCHS_NEW = 1\n","\n","import time\n","import datetime\n","\n","words = []\n","feature_matrix = []\n","labels = []"],"metadata":{"id":"63l139DK2sJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"E6ATJGPn20_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_t0 = time.time()\n","\n","for epoch in range(0, EPOCHS_NEW):\n","  # ========================================\n","  #               Training\n","  # ========================================\n","    \n","  # Perform one full pass over the training set.\n","\n","  print(\"\")\n","  print('======== Epoch {:} / {:} ========'.format(epoch + 1, EPOCHS_NEW))\n","  print('Training...')\n","\n","  # Measure how long the training epoch takes.\n","  t0 = time.time()\n","\n","  # Reset the total loss for this epoch.\n","  total_train_loss = 0\n","\n","  for step, batch in enumerate(loader_train_data):\n","    if step % 40 == 0 and not step == 0:\n","      # Calculate elapsed time in minutes.\n","      elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(loader_train_data), elapsed))\n","\n","    input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n","    attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n","    emotion_scores = batch[\"emotion_scores\"].to(device, dtype = torch.float)\n","\n","    feature_extractor.zero_grad()\n","\n","    input_ids = input_ids.squeeze(1)\n","\n","    with torch.no_grad():\n","      logits, CLS, hid = feature_extractor(input_ids, attention_mask=attention_mask)\n","\n","    words.append(hid[0])\n","    feature_matrix.append(CLS)\n","    labels.append(emotion_scores)\n","\n","  print(\"\")\n","  print(\"Running Validation...\")\n","\n","  t0 = time.time()\n","\n","  total_eval_loss = 0\n","  nb_eval_steps = 0\n","\n","  for batch in loader_valid_data:\n","\n","    input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n","    attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n","    emotion_scores = batch[\"emotion_scores\"].to(device, dtype = torch.float)\n","\n","    input_ids = input_ids.squeeze(1)\n","\n","    with torch.no_grad():\n","      logits, CLS, hid = feature_extractor(input_ids, attention_mask=attention_mask)\n","    \n","    words.append(hid[0]) \n","    feature_matrix.append(CLS)\n","    labels.append(emotion_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nGySr-dv3cTt","executionInfo":{"status":"ok","timestamp":1650138475039,"user_tz":-240,"elapsed":46147,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"9346f735-ed40-4da4-dffc-5a9b625d297d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 1 ========\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["  Batch    40  of    478.    Elapsed: 0:00:03.\n","  Batch    80  of    478.    Elapsed: 0:00:06.\n","  Batch   120  of    478.    Elapsed: 0:00:10.\n","  Batch   160  of    478.    Elapsed: 0:00:13.\n","  Batch   200  of    478.    Elapsed: 0:00:16.\n","  Batch   240  of    478.    Elapsed: 0:00:20.\n","  Batch   280  of    478.    Elapsed: 0:00:23.\n","  Batch   320  of    478.    Elapsed: 0:00:26.\n","  Batch   360  of    478.    Elapsed: 0:00:30.\n","  Batch   400  of    478.    Elapsed: 0:00:33.\n","  Batch   440  of    478.    Elapsed: 0:00:37.\n","\n","Running Validation...\n"]}]},{"cell_type":"code","source":["sentences_test = test_df_final.Sentence.values"],"metadata":{"id":"-GAENTq169uS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion_scores_test = test_df_final.iloc[:,1:].values\n","print(emotion_scores_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRwLzAuw7AIC","executionInfo":{"status":"ok","timestamp":1650138568807,"user_tz":-240,"elapsed":325,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"c82bab04-c236-422f-d591-089b055c2618"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," ...\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]]\n"]}]},{"cell_type":"code","source":["test_dataset = emoClass(test_df_final, sentences_test, emotion_scores_test, tokenizer, MAX_LEN)\n","print(test_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1FWusuhT7JgR","executionInfo":{"status":"ok","timestamp":1650138752972,"user_tz":-240,"elapsed":317,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"d92e4c8c-751c-4b7c-b88d-2ce14bd50f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'sentence': 'what doing sp not talking about just going into your local starbucks and talking to everybody there i find', 'input_ids': tensor([[  101,  2054,  2725, 11867,  2025,  3331,  2055,  2074,  2183,  2046,\n","          2115,  2334, 29500,  1998,  3331,  2000,  7955,  2045,  1045,  2424,\n","           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'emotion_scores': tensor([0., 0., 0., 1., 0., 0.])}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}]},{"cell_type":"code","source":["TEST_BATCH_SIZE = 32"],"metadata":{"id":"dhkER6-d70o5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loader_test_data = DataLoader(\n","              test_dataset,\n","              sampler = torch.utils.data.SequentialSampler(test_dataset),\n","              batch_size = TEST_BATCH_SIZE\n","          )"],"metadata":{"id":"WQjkwb3f79Jf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_extractor.eval()\n","\n","predictions , true_labels = [], []\n","\n","for batch in loader_test_data:\n","  input_ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n","  attention_mask = batch[\"attention_mask\"].to(device, dtype = torch.long)\n","  emotion_scores = batch[\"emotion_scores\"].to(device, dtype = torch.float)\n","\n","  input_ids = input_ids.squeeze(1)\n","\n","  with torch.no_grad():\n","    logits,out, hid = feature_extractor(input_ids, attention_mask=attention_mask)\n","    words.append(hid[0])\n","    feature_matrix.append(out)\n","    labels.append(emotion_scores)\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = emotion_scores.to('cpu').numpy()\n","\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keOT5jPf8WXn","executionInfo":{"status":"ok","timestamp":1650139257741,"user_tz":-240,"elapsed":14640,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"96e1d982-7215-49f8-98d8-09d1b6cef700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["    DONE.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","from scipy.stats import pearsonr"],"metadata":{"id":"FL2Vk8dp9rVw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flat_predictions = np.concatenate(predictions, axis=0)\n","\n","flat_predictions = flat_predictions.flatten()\n","\n","flat_true_labels = np.concatenate(true_labels, axis=0)"],"metadata":{"id":"6smFGIyE9v5-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(flat_true_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLqc1VLN-0Os","executionInfo":{"status":"ok","timestamp":1650139760353,"user_tz":-240,"elapsed":316,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"24b22558-6734-4c28-c0b8-ce2f1dcf3ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," ...\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 1. 0. 0.]]\n"]}]},{"cell_type":"code","source":["print(len(flat_predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fknD0kK1AdBE","executionInfo":{"status":"ok","timestamp":1650139993757,"user_tz":-240,"elapsed":5,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"8ba2ec08-c3bd-4325-a632-8a2520c4587f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28992\n"]}]},{"cell_type":"code","source":["from sklearn import metrics"],"metadata":{"id":"XwIcnoLi-ek2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score_list = []\n","for i, value in enumerate(flat_true_labels):\n","  for score in value:\n","    score_list.append(int(score))"],"metadata":{"id":"njON7DiU_jC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(score_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBJk4C0pAMlr","executionInfo":{"status":"ok","timestamp":1650140052020,"user_tz":-240,"elapsed":12,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"2ead1dd7-2e70-426a-f345-a1b5de5fb14b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28992\n"]}]},{"cell_type":"code","source":["flat_polarities = [int(log>=0) for log in flat_predictions]\n","true_polarities = score_list\n","\n","print(len(flat_polarities))\n","# Calculate the MCC\n","cc = pearsonr(score_list, flat_predictions)[0]\n","MAE = mean_absolute_error(score_list, flat_predictions)\n","acc = metrics.accuracy_score(flat_polarities, true_polarities)\n","f1 = metrics.f1_score(true_polarities, flat_polarities)\n","print('Total CC from simple BERT: %.3f' % cc) # --> Double Check the results from the feature extractors correspond to previous ones\n","print('Total MAE from simple BERT: %.3f' % MAE)\n","print('Total Acc from simple BERT: %.3f' % acc)\n","print('Total F1 from simple BERT: %.3f' % f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eaf26pxr-LCY","executionInfo":{"status":"ok","timestamp":1650140095241,"user_tz":-240,"elapsed":881,"user":{"displayName":"Ayushi Amin","userId":"07673479535746723990"}},"outputId":"06fbc258-bec7-4822-b43f-9f148b84cc9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28992\n","Total CC from simple BERT: 0.438\n","Total MAE from simple BERT: 2.531\n","Total Acc from simple BERT: 0.845\n","Total F1 from simple BERT: 0.395\n"]}]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"s6e39jwdA_A0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATA = torch.cat(feature_matrix, dim=0).cpu()"],"metadata":{"id":"MrVbgLV2BDFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_hiddens = torch.cat([words[k] for k in range(len(words))],dim=0).cpu()"],"metadata":{"id":"hI0HDyrmBhPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = [lab.cpu().float() for lab in labels]\n","lab_tot = torch.cat(labels,dim=0)"],"metadata":{"id":"V9JGUNf4BnXF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Bert_dict = {'Data':DATA, 'words': last_hiddens,'level':lab_tot}\n","  \n","with open('/content/drive/MyDrive/Dissertation/dataset/data/BERT_features.pkl', 'wb') as fp:\n","  pickle.dump(Bert_dict, fp)"],"metadata":{"id":"2oRkGdxhB0vy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Dissertation/dataset/data/BERT_features.pkl', 'rb') as fp:\n","  testDict = pickle.load(fp)"],"metadata":{"id":"58LO87MiCEag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(testDict))\n","print(len(testDict))\n","print(testDict.keys())\n","print(list(testDict.items())[:5])"],"metadata":{"id":"wR6FIox1CP6E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650167184207,"user_tz":-240,"elapsed":510,"user":{"displayName":"ayushi amin","userId":"16559211414148572210"}},"outputId":"6584d3ae-942a-4de3-9da3-efc284ca4c58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dict'>\n","3\n","dict_keys(['Data', 'words', 'level'])\n","[('Data', tensor([[-0.6896,  0.4095, -0.8756,  ..., -0.0558,  0.5297,  0.6678],\n","        [-0.6113,  0.4857, -0.7064,  ..., -0.0250,  0.6356,  0.5880],\n","        [-0.6002,  0.5228, -0.8050,  ..., -0.1901,  0.6196,  0.6203],\n","        ...,\n","        [ 0.0092,  0.2866, -0.8131,  ...,  0.6850,  0.7082,  0.0041],\n","        [-0.1330,  0.4667, -0.6513,  ...,  0.8437,  0.7242,  0.2770],\n","        [ 0.0011,  0.5065, -0.7625,  ...,  0.7801,  0.7613, -0.0789]])), ('words', tensor([[[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [-0.7390,  0.2383,  0.3255,  ...,  0.6723,  0.6231, -0.2401],\n","         [-0.9914,  0.4889, -0.7340,  ...,  0.5526,  0.9601, -0.4202],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]],\n","\n","        [[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [ 0.6695, -0.2074,  0.3941,  ...,  0.2685,  0.4885, -0.2970],\n","         [ 0.3694, -0.2842,  0.5493,  ...,  0.0729,  0.3317, -0.3431],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]],\n","\n","        [[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [ 0.6695, -0.2074,  0.3941,  ...,  0.2685,  0.4885, -0.2970],\n","         [ 0.3694, -0.2842,  0.5493,  ...,  0.0729,  0.3317, -0.3431],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]],\n","\n","        ...,\n","\n","        [[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [-0.3039,  0.4917,  0.5020,  ...,  0.7546,  0.6805,  0.2953],\n","         [ 0.5278, -0.6758,  0.5321,  ...,  0.0723,  0.3570, -1.5132],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]],\n","\n","        [[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [ 0.6695, -0.2074,  0.3941,  ...,  0.2685,  0.4885, -0.2970],\n","         [ 0.3694, -0.2842,  0.5493,  ...,  0.0729,  0.3317, -0.3431],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]],\n","\n","        [[ 0.1606, -0.2876, -0.3232,  ..., -0.0352,  0.0288,  0.1569],\n","         [ 0.5437,  0.4724, -0.1754,  ...,  0.6423,  0.4748,  0.3125],\n","         [ 0.7764, -0.7659, -0.3301,  ..., -0.0814,  0.5018, -0.5376],\n","         ...,\n","         [ 0.0078, -0.2332,  0.2640,  ..., -0.0560, -0.2933,  0.2840],\n","         [-0.0727, -0.3865,  0.1692,  ...,  0.0833, -0.3621,  0.2327],\n","         [ 0.1257, -0.3715,  0.0673,  ...,  0.3249, -0.6364,  0.1751]]])), ('level', tensor([[0., 1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.]]))]\n"]}]}]}